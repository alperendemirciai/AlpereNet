Training started!
Epochs:  1000
Learning Rate:  0.5
Epoch 0 Loss: 2.3025492257397873
Epoch 10 Loss: 2.3016371689395076
Epoch 20 Loss: 2.301313029435791
Epoch 30 Loss: 2.3011976604692457
Epoch 40 Loss: 2.3011553912051577
Epoch 50 Loss: 2.3011385027456095
Epoch 60 Loss: 2.301129292933185
Epoch 70 Loss: 2.301123664762949
Epoch 80 Loss: 2.3011188199987234
Epoch 90 Loss: 2.301113704426322
Epoch 100 Loss: 2.3011082627207933
Epoch 110 Loss: 2.3011023720510115
Epoch 120 Loss: 2.301095691549239
Epoch 130 Loss: 2.3010880246313503
Epoch 140 Loss: 2.3010791269913144
Epoch 150 Loss: 2.3010686721941465
Epoch 160 Loss: 2.301056214139838
Epoch 170 Loss: 2.30104113768227
Epoch 180 Loss: 2.3010225929158574
Epoch 190 Loss: 2.300999400238656
Epoch 200 Loss: 2.3009697477183333
Epoch 210 Loss: 2.300930670453079
Epoch 220 Loss: 2.3008773791016752
Epoch 230 Loss: 2.3008015408938958
Epoch 240 Loss: 2.300687745536561
Epoch 250 Loss: 2.3005055363898723
Epoch 260 Loss: 2.300188082277755
Epoch 270 Loss: 2.2995521046156466
Epoch 280 Loss: 2.2979431686700873
Epoch 290 Loss: 2.291321248841382
Epoch 300 Loss: 2.179461522015235
Epoch 310 Loss: 2.042880442379914
Epoch 320 Loss: 1.9165930585294488
Epoch 330 Loss: 1.8374103049744708
Epoch 340 Loss: 1.7328314495765753
Epoch 350 Loss: 1.766836485690281
Epoch 360 Loss: 1.5944096490517785
Epoch 370 Loss: 1.4569326343370077
Epoch 380 Loss: 1.375040274094461
Epoch 390 Loss: 1.0323979532185408
Epoch 400 Loss: 0.7583180739567951
Epoch 410 Loss: 1.1735346889047553
Epoch 420 Loss: 0.6559537163675088
Epoch 430 Loss: 0.5454925735179765
Epoch 440 Loss: 0.4093380484355886
Epoch 450 Loss: 0.35531821403731567
Epoch 460 Loss: 0.3602972728984429
Epoch 470 Loss: 0.3001008519203588
Epoch 480 Loss: 0.2731623641032975
Epoch 490 Loss: 0.24669421087704693
Epoch 500 Loss: 0.20139836652257165
Epoch 510 Loss: 0.1950602452958716
Epoch 520 Loss: 0.7342940229743888
Epoch 530 Loss: 2.1749980569716674
Epoch 540 Loss: 1.283467586749587
Epoch 550 Loss: 1.2078890829219555
Epoch 560 Loss: 0.33493611502964027
Epoch 570 Loss: 0.2678622743695557
Epoch 580 Loss: 0.22897331650707697
Epoch 590 Loss: 0.20062685958323087
Epoch 600 Loss: 0.17887089766504474
Epoch 610 Loss: 0.16123745713751841
Epoch 620 Loss: 0.14649739025007671
Epoch 630 Loss: 0.13388258382313944
Epoch 640 Loss: 0.12310573477211896
Epoch 650 Loss: 0.1137133220300935
Epoch 660 Loss: 0.10542272525937658
Epoch 670 Loss: 0.09804030809639927
Epoch 680 Loss: 0.0914410805770712
Epoch 690 Loss: 0.08552743975362413
Epoch 700 Loss: 0.08010585223492804
Epoch 710 Loss: 0.07506198658921731
Epoch 720 Loss: 0.07036849338773996
Epoch 730 Loss: 0.06603946536823643
Epoch 740 Loss: 0.06202305993794111
Epoch 750 Loss: 0.05828826487673868
Epoch 760 Loss: 0.054836243087878475
Epoch 770 Loss: 0.051633738374397324
Epoch 780 Loss: 0.04862032520284438
Epoch 790 Loss: 0.045799000632293745
Epoch 800 Loss: 0.04315178222158618
Epoch 810 Loss: 0.04067146975335357
Epoch 820 Loss: 0.038355549900072276
Epoch 830 Loss: 0.03619739220807295
Epoch 840 Loss: 0.03412593180958071
Epoch 850 Loss: 0.03218059788117199
Epoch 860 Loss: 0.03035472904222584
Epoch 870 Loss: 0.0286454187001042
Epoch 880 Loss: 0.02701657131574596
Epoch 890 Loss: 0.02547241996334357
Epoch 900 Loss: 0.024030978211037037
Epoch 910 Loss: 0.022621388123253833
Epoch 920 Loss: 0.021288433674670246
Epoch 930 Loss: 0.020060735439693913
Epoch 940 Loss: 0.01891910818392744
Epoch 950 Loss: 0.017860569208609366
Epoch 960 Loss: 0.016890383165661445
Epoch 970 Loss: 0.015993782806126122
Epoch 980 Loss: 0.015158911450600833
Epoch 990 Loss: 0.014340761250523044
Test Accuracy: 0.9595238095238096
Train Accuracy: 0.998125
Final Loss: 0.014340761250523044
Shapes of the data:
(784, 33600) (10, 33600) (784, 8400) (10, 8400)
2024-03-30 01:02:15.757 Python[27088:2370685] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.
Accuracy: 0.9595238095238096
Predicted labels:  1    3748
7    3521
3    3488
9    3351
2    3347
6    3314
0    3307
4    3253
8    3239
5    3032
Name: count, dtype: int64
Real labels:  1    3747
7    3521
3    3481
9    3350
2    3342
6    3310
0    3305
4    3258
8    3250
5    3036
Name: count, dtype: int64